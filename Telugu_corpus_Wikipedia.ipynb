{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ba84162-2b1a-414f-8d67-e2ab9fcee73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d859010-e5a8-489b-95f5-91f61c35f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_telugu_articles(category='Category:Telugu_language', limit=10):\n",
    "    base_url = \"https://te.wikipedia.org/wiki/\"\n",
    "    api_url = \"https://te.wikipedia.org/w/api.php\"  # Correctly placed definition\n",
    "    articles = {}\n",
    "\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': category,\n",
    "        'cmlimit': limit,\n",
    "    }\n",
    "    response = requests.get(api_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            return data.get('query', {}).get('categorymembers', [])\n",
    "        except requests.exceptions.JSONDecodeError:\n",
    "            print(\"Error: Response is not JSON.\")\n",
    "            print(response.text)\n",
    "    else:\n",
    "        print(f\"HTTP Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e7ee16a-88d7-46a7-9125-f55e423ad211",
   "metadata": {},
   "outputs": [],
   "source": [
    " def scrape_article_content(title):\n",
    "    \"\"\"\n",
    "    Scrape content from a specific Telugu Wikipedia article.\n",
    "    \"\"\"\n",
    "    base_url = \"https://te.wikipedia.org/wiki/\"\n",
    "    article_url = base_url + title.replace(' ', '_')\n",
    "\n",
    "    try:\n",
    "        response = requests.get(article_url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            content_div = soup.find('div', class_='mw-parser-output')\n",
    "            if content_div:\n",
    "                paragraphs = content_div.find_all('p')\n",
    "                return \"\\n\".join(p.text for p in paragraphs if p.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {article_url}: {e}\")\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78a41092-e10c-4f10-8452-a17488e92bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_all_articles_to_file(articles, output_file='telugu_articles.txt'):\n",
    "    \"\"\"\n",
    "    Save all articles to a single text file.\n",
    "    :param articles: Dictionary of article titles and their content.\n",
    "    :param output_file: Path to the output text file.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        for title, content in articles.items():\n",
    "            file.write(f\"### {title} ###\\n\")  # Add a title header for each article\n",
    "            file.write(content)\n",
    "            file.write(\"\\n\\n\")  # Separate articles with blank lines\n",
    "    print(f\"All articles saved in: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8a8686c-e59b-472a-8dd4-45a4f328973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching content for: తెలుగు\n",
      "Fetching content for: అధికార భాష\n",
      "Fetching content for: అరసున్న\n",
      "Fetching content for: ఆంధ్రప్రదేశ్ తెలుగు భాషా దినోత్సవం\n",
      "Fetching content for: కీర్తన\n",
      "Fetching content for: గోదావరి యాస\n",
      "Fetching content for: జంట పదాలు\n",
      "Fetching content for: ఢిల్లీ తెలుగు అకాడమీ\n",
      "Fetching content for: తు.చ.తప్పకుండా\n",
      "Fetching content for: తెలంగాణ యాస\n",
      "Fetching content for: తెలుగు అకాడమి\n",
      "Fetching content for: తెలుగు అక్షరాలు\n",
      "Fetching content for: తెలుగు కవిత్వం\n",
      "Fetching content for: తెలుగు కవులు - బిరుదులు\n",
      "Fetching content for: తెలుగు ప్రథమాలు\n",
      "Fetching content for: తెలుగు మాధ్యమాల దినోత్సవం\n",
      "Fetching content for: తెలుగు రాష్ట్రాలు\n",
      "Fetching content for: తెలుగు విజయం\n",
      "Fetching content for: తెలుగు విజ్ఞాన సర్వస్వం\n",
      "Fetching content for: తెలుగు సభలు\n",
      "Fetching content for: తెలుగుతల్లి\n",
      "Fetching content for: తెలుగులో విద్యాబోధన\n",
      "Fetching content for: తెలుగులో వైకల్పనలు\n",
      "Fetching content for: దేశ భాషలందు తెలుగు లెస్స\n",
      "Fetching content for: నాగబు\n",
      "Fetching content for: నామవాచకం (తెలుగు వ్యాకరణం)\n",
      "Fetching content for: నాలుగవ ప్రపంచ తెలుగు మహాసభలు\n",
      "Fetching content for: నిఘంటువు\n",
      "Fetching content for: పొట్టి శ్రీరాములు తెలుగు విశ్వవిద్యాలయం\n",
      "Fetching content for: పొట్టి శ్రీరాములు తెలుగు విశ్వవిద్యాలయము ప్రచురణలు\n",
      "Fetching content for: ప్రపంచ తెలుగు మహాసభలు\n",
      "Fetching content for: ప్రవాసాంధ్రులు\n",
      "Fetching content for: ప్రాచీన భాష\n",
      "Fetching content for: భారతదేశంలోని రాష్ట్రాల వారీగా తెలుగు మాట్లాడే ప్రజల జాబితా\n",
      "Fetching content for: మొదటి ప్రపంచ తెలుగు మహాసభలు\n",
      "Fetching content for: రెండవ ప్రపంచ తెలుగు మహాసభలు\n",
      "Fetching content for: విక్షనరీ\n",
      "Fetching content for: విలేజ్ వ్యాన్\n",
      "Fetching content for: శబ్దరత్నాకరము\n",
      "Fetching content for: వికీపీడియా:సాధారణ పదదోషాలు - తప్పొప్పుల పట్టిక\n",
      "Fetching content for: హ\n",
      "Fetching content for: వర్గం:అంతర్జాలంలో తెలుగు\n",
      "Fetching content for: వర్గం:ఆత్మకథలు\n",
      "Fetching content for: వర్గం:కంప్యూటర్లో తెలుగు\n",
      "Fetching content for: వర్గం:తెలుగు అంతర్జాలము\n",
      "Fetching content for: వర్గం:తెలుగు అధ్యయన కేంద్రాలు\n",
      "Fetching content for: వర్గం:తెలుగు అనువాద పుస్తకాలు\n",
      "Fetching content for: వర్గం:తెలుగు ఆచార్యులు\n",
      "Fetching content for: వర్గం:తెలుగు భాష\n",
      "Fetching content for: వర్గం:తెలుగు భాష చరిత్ర\n",
      "Fetching content for: వర్గం:తెలుగు రాజులు\n",
      "Fetching content for: వర్గం:తెలుగు లలితా గీతాలు\n",
      "Fetching content for: వర్గం:తెలుగు విమర్శకులు\n",
      "Fetching content for: వర్గం:తెలుగు విశ్వవిద్యాలయం\n",
      "Fetching content for: వర్గం:తెలుగు శాసనాలు\n",
      "Fetching content for: వర్గం:తెలుగు సాహిత్యం\n",
      "Fetching content for: వర్గం:తెలుగు సినిమా\n",
      "Fetching content for: వర్గం:నానీల కవులు\n",
      "Fetching content for: వర్గం:భాషావేత్తలు\n",
      "All articles saved in: telugu_articles.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Fetch articles\n",
    "category_members = fetch_telugu_articles(category='Category:తెలుగు', limit=1000)\n",
    "\n",
    "# Step 2: Scrape content for each article\n",
    "articles = {}\n",
    "for member in category_members:\n",
    "    title = member.get('title', 'Untitled')\n",
    "    print(f\"Fetching content for: {title}\")\n",
    "    content = scrape_article_content(title)\n",
    "    if content:\n",
    "        articles[title] = content\n",
    "\n",
    "# Step 3: Save all articles in a single text file\n",
    "if articles:\n",
    "    save_all_articles_to_file(articles)\n",
    "else:\n",
    "    print(\"No articles fetched.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b0d15f9-d9d2-4025-a919-b10738412d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response Content: {\"batchcomplete\":\"\",\"query\":{\"categorymembers\":[]}}\n"
     ]
    }
   ],
   "source": [
    "def debug_api_response(category='Category:Telugu_language', limit=10):\n",
    "    api_url = \"https://te.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'list': 'categorymembers',\n",
    "        'cmtitle': category,\n",
    "        'cmlimit': limit,\n",
    "    }\n",
    "    response = requests.get(api_url, params=params)\n",
    "    print(\"Status Code:\", response.status_code)\n",
    "    print(\"Response Content:\", response.text)\n",
    "\n",
    "debug_api_response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff998205-3176-4904-bf62-fdc60626cb94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
